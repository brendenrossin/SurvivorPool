# ğŸ“ Railway Deployment Lessons Learned

## âš ï¸ CRITICAL: Read This Before Making Changes

This document contains hard-learned lessons from Railway deployment debugging. **Always check this before making deployment changes.**

---

## ğŸ” OAuth Token Persistence (CRITICAL FIX - Nov 2025)

### âš ï¸ Problem: Tokens Expiring Every 1-2 Weeks
**Root Cause:** Refreshed OAuth tokens were saved to **local files**, but Railway containers are **ephemeral**. Files don't persist across:
- Container restarts
- Deployments
- Cron job completions

**What was happening:**
1. Token refreshes successfully âœ…
2. Saved to `.credentials/.railway_oauth_token_refreshed.txt` âœ…
3. Container destroyed â†’ **File deleted** âŒ
4. Next run loads **old token** from environment variable âŒ
5. Google eventually revokes the old refresh token ğŸ’¥

### âœ… Solution: Database-Backed Token Persistence
**Fixed in:** `api/oauth_manager.py` (Nov 2025)

Now refreshed tokens are saved to **PostgreSQL** (`job_meta` table):
```python
# Priority 1: Load from database (persists across restarts)
job_meta = db.query(JobMeta).filter(JobMeta.job_name == 'oauth_token').first()

# Priority 2: Fall back to environment variable (first run only)
token_json = os.getenv('GOOGLE_OAUTH_TOKEN_JSON')

# After refresh: Save to database
job_meta.message = refreshed_token  # Persists across Railway restarts!
```

**Result:** OAuth tokens now auto-refresh for **~6 months** without manual intervention! ğŸ‰

### ğŸ“‹ One-Time Setup (when refresh token is revoked)
```bash
# 1. Generate fresh token locally
rm -f token.json
python scripts/testing/test_personal_sheets.py

# 2. Update Railway environment variable
cat .credentials/.railway_oauth_token_FRESH.txt | pbcopy
# Railway Dashboard â†’ Variables â†’ GOOGLE_OAUTH_TOKEN_JSON â†’ Paste

# 3. First cron run saves to database
# Future runs use database token automatically!
```

---

## ğŸš€ Railway Deployment - DO's

### âœ… Working Architecture
- **USE Dockerfile approach** with `CMD ["./start.sh"]`
- **USE start.sh script** with proper Streamlit flags
- **KEEP railway.json minimal** - no custom startCommand
- **INCLUDE database initialization** in start.sh before Streamlit

### âœ… Required Streamlit Flags for Railway
```bash
streamlit run app/main.py \
    --server.port=$PORT \
    --server.address=0.0.0.0 \
    --server.headless=true \
    --server.enableCORS=false \
    --server.enableXsrfProtection=false
```

### âœ… Testing Protocol
1. **ALWAYS test locally first** before pushing to Railway
2. **Test exact command syntax** in local shell scripts
3. **Verify environment variables** are properly expanded
4. **Check git history** for working commits when things break

---

## ğŸš« Railway Deployment - DON'Ts

### âŒ NEVER Use These Patterns
- **DON'T use railway.json startCommand** - breaks critical Streamlit flags
- **DON'T use basic `streamlit run`** without Railway-specific flags
- **DON'T skip local testing** of deployment commands
- **DON'T deploy without checking working git history**

### âŒ Variable Expansion Issues
- **DON'T use `$PORT`** directly in railway.json (doesn't expand)
- **DON'T use `--server.port $PORT`** (space causes parsing issues)
- **DON'T assume Railway env vars** work same as local

---

## ğŸ” Debugging Process

### When Getting 502 Errors:
1. **Check git history** - find last working commit
2. **Compare railway.json** - likely startCommand issue
3. **Verify Dockerfile CMD** - should use start.sh
4. **Check Streamlit flags** - Railway needs specific flags

### Error Patterns & Solutions:
```
Error: Invalid value for '--server.port': '$PORT' is not a valid integer
â†’ Solution: Use start.sh with proper variable handling

502 Application failed to respond
â†’ Solution: Revert to Dockerfile CMD approach

Container stopping after database init
â†’ Solution: Remove startCommand from railway.json
```

---

## ğŸ“ File Structure - Working State

### railway.json (MINIMAL - Working)
```json
{
  "$schema": "https://railway.app/railway.schema.json",
  "build": {
    "builder": "DOCKERFILE"
  },
  "deploy": {
    "restartPolicyType": "ON_FAILURE",
    "restartPolicyMaxRetries": 10
  }
}
```

### start.sh (COMPLETE - Working)
```bash
#!/bin/bash
# Database initialization
python init_db_railway.py

# Port handling
if [ -z "$PORT" ]; then
    PORT=8080
fi

# Streamlit with ALL required flags
exec streamlit run app/main.py \
    --server.port=$PORT \
    --server.address=0.0.0.0 \
    --server.headless=true \
    --server.enableCORS=false \
    --server.enableXsrfProtection=false
```

---

## ğŸ¯ Environment Variables (Railway Dashboard)

### Required Variables:
```
DATABASE_URL=postgresql://postgres:...@postgres.railway.internal:5432/railway
GOOGLE_OAUTH_TOKEN_JSON={"token": "...", "refresh_token": "..."}
GOOGLE_SHEETS_SPREADSHEET_ID=12dM-Ks5JLmjSQPWyVsigZIn6RguZx6m47yl-khamHFY
GOOGLE_SHEETS_PICKS_RANGE=Picks!A1:Z5000
NFL_SEASON=2025
SCORES_PROVIDER=espn
ENVIRONMENT=railway
```

---

## ğŸ”„ Data Ingestion Strategy

### Working Approach:
1. **Database init** happens in start.sh
2. **Mock data population** if database empty
3. **OAuth ingestion** separate from startup (prevents timeouts)
4. **NFL scores** updated independently

### DON'T:
- **DON'T run data ingestion** in railway.json startCommand
- **DON'T block Streamlit startup** with slow operations
- **DON'T fail deployment** if OAuth/external APIs fail

---

## ğŸ§ª Local Testing Commands

### Test Streamlit syntax:
```bash
PORT=8530 && streamlit run app/main.py --server.port=$PORT --server.address=0.0.0.0
```

### Test start.sh script:
```bash
export PORT=8531
export DATABASE_URL="sqlite:///debug_output/local_survivor.db"
./start.sh
```

---

## ğŸ“ Commit Message Patterns

### Good commits:
- "REVERT to working Dockerfile approach"
- "Fix Streamlit command syntax - tested locally first"
- "Add database initialization to start.sh"

### Bad commits:
- "Try different Railway startup"
- "Fix deployment issues"
- "Update config"

---

## ğŸ­ Last Working State (Reference)

**Commit:** `d6acfb5` - "Fix mock data population with Railway-specific script"
**Key:** Used Dockerfile CMD with start.sh, no railway.json startCommand

When in doubt, compare current state to this working commit.

---

## ğŸ”‘ Google OAuth Token Revocation (CRITICAL)

### Problem
**Date:** 2025-10-05
**Symptom:** Sheets ingestion failing with `invalid_grant: Token has been expired or revoked`

**Root Cause:**
Google revokes OAuth refresh tokens if they're not used for extended periods (typically 6 months for production apps, shorter for apps in testing mode). Our access token expired and sat dormant without being refreshed, causing the refresh token to also be revoked.

### Solution

**Immediate Fix:**
1. Delete old `token.json`: `rm -f token.json`
2. Regenerate fresh credentials: `python scripts/testing/test_personal_sheets.py`
3. Browser will open for re-authentication
4. Encode for Railway: New token saved to `.credentials/.railway_oauth_token_FRESH.txt`
5. Update Railway environment variable `GOOGLE_OAUTH_TOKEN_JSON` with fresh base64 token

**Permanent Prevention:**
Created proactive token refresh system:

1. **Proactive Refresh Job** (`jobs/refresh_oauth_token.py`)
   - Checks and refreshes OAuth token before expiry
   - Saves refreshed tokens for Railway updates
   - Returns error codes for monitoring

2. **Integrated into Sheets Cron** (`cron/sheets_ingestion.py`)
   - Step 1: Refresh OAuth token
   - Step 2: Ingest sheets data
   - Ensures token is fresh before every ingestion

3. **Health Monitoring** (`jobs/monitor_oauth_health.py`)
   - Monitors `job_meta` table for OAuth failures
   - Alerts on authentication errors
   - Tracks time since last successful ingestion

### Key Learnings

- âš ï¸ **OAuth tokens need regular refresh** - don't let them sit dormant
- ğŸ”„ **Refresh before use** - always refresh token proactively before API calls
- ğŸ“Š **Monitor job_meta** - watch for OAuth error patterns in job messages
- ğŸš¨ **Alert on failures** - catch token issues before they impact users
- ğŸ”§ **Manual Railway updates required** - Railway env vars can't be updated from within the app (security feature)

### Testing Notes

Local testing requires setting env var:
```bash
export GOOGLE_OAUTH_TOKEN_JSON="<base64_token>"
python jobs/refresh_oauth_token.py
```

On Railway, env var is automatically available to cron jobs.

### Deployment Status
- âœ… Fresh OAuth token generated (2025-10-18)
- âœ… Railway production env var updated
- âœ… Improved OAuth manager to handle expired access tokens (2025-10-18)
- âœ… **AUTO-REFRESH NOW WORKS!** - No manual token updates needed for 6+ months
- âœ… Proactive refresh added to sheets cron
- âœ… Health monitoring script created
- ğŸ“ Documentation updated

### Final Solution (2025-10-18)
**Key Improvement:** Modified `api/oauth_manager.py` to aggressively refresh expired access tokens:
- Checks for expired/invalid access tokens on every API call
- Automatically uses refresh_token to get new access token
- New access tokens valid for ~1 hour
- Refresh token valid for 6+ months
- **System now fully automatic - no manual intervention needed!**

---

*ğŸ’¡ Always update this document when learning new lessons or solving new deployment issues.*
*ğŸ’¡ Always update this document when learning new lessons or solving new deployment issues.*
*ğŸ’¡ Always update this document when learning new lessons or solving new deployment issues.*
*ğŸ’¡ Always update this document when learning new lessons or solving new deployment issues.*where